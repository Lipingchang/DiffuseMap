[{"original_text": "还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力。[黑线]", "username": "王威廉", "province": 400, "statuses_count": 2449, "friends_count": 337, "city": 1, "text": "还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力。[黑线]", "user_description": "NLP, Machine Learning, and Speech @ CMU http://www.cs.cmu.edu/~yww/", "mid": "3747400319453702", "verified_reason": "", "followers_count": 43783, "parent": "", "t": 1408933322, "gender": "m", "verified": false, "verified_type": -1, "uid": "1657470871"}, {"original_text": "//@王威廉: 还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力.", "username": "icecile", "province": 44, "statuses_count": 6075, "friends_count": 418, "city": 1, "text": "", "user_description": "成长的母亲，过期的女友。一颗自得其乐的心。", "mid": "3747400843288162", "verified_reason": "", "followers_count": 1238, "parent": "3747400319453702", "t": 1408933447, "gender": "f", "verified": false, "verified_type": -1, "uid": "1653959761"}, {"original_text": "//@王威廉: 还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力", "username": "WeiHu1918", "province": 33, "statuses_count": 31959, "friends_count": 1875, "city": 1, "text": "", "user_description": "神 爱 世 人 ， 甚 至 将 他 的 独 生 子 赐 给 他 们 ， 叫 一 切 信 他 的 ， 不 至 灭 亡 ， 反 得 永 生 。", "mid": "3747401216647114", "verified_reason": "", "followers_count": 5588, "parent": "3747400319453702", "t": 1408933536, "gender": "m", "verified": false, "verified_type": -1, "uid": "3973508856"}, {"original_text": "//@王威廉: 还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？", "username": "THB-HEU", "province": 23, "statuses_count": 373, "friends_count": 725, "city": 1, "text": "", "user_description": "", "mid": "3747401325717071", "verified_reason": "", "followers_count": 689, "parent": "3747400319453702", "t": 1408933562, "gender": "m", "verified": false, "verified_type": 220, "uid": "1240989305"}, {"original_text": "坏名字//@王威廉:还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？", "username": "raogaoqi", "province": 11, "statuses_count": 6449, "friends_count": 786, "city": 8, "text": "坏名字", "user_description": "基督徒，自然语言处理，语言政策～北语小博", "mid": "3747401564834395", "verified_reason": "", "followers_count": 1459, "parent": "3747400319453702", "t": 1408933619, "gender": "m", "verified": false, "verified_type": 220, "uid": "1242190153"}, {"original_text": "这也是常见错误 //@王威廉:还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？", "username": "winsty", "province": 81, "statuses_count": 2222, "friends_count": 294, "city": 14, "text": "这也是常见错误 ", "user_description": "HKUST CSE PhD, Computer Vision and Machine Learning", "mid": "3747401624362819", "verified_reason": "", "followers_count": 5949, "parent": "3747400319453702", "t": 1408933633, "gender": "m", "verified": false, "verified_type": -1, "uid": "1218274631"}, {"original_text": "转发微博", "username": "kilkennypaopao", "province": 400, "statuses_count": 600, "friends_count": 188, "city": 15, "text": "转发微博", "user_description": "", "mid": "3747401686778854", "verified_reason": "", "followers_count": 67, "parent": "3747400319453702", "t": 1408933648, "gender": "f", "verified": false, "verified_type": -1, "uid": "3041845821"}, {"original_text": "//@王威廉: 还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力", "username": "朱凌凌00", "province": 32, "statuses_count": 1000, "friends_count": 724, "city": 1, "text": "", "user_description": "直道相思了无意，未妨惆怅是清狂", "mid": "3747402060516397", "verified_reason": "", "followers_count": 2337, "parent": "3747400319453702", "t": 1408933737, "gender": "f", "verified": false, "verified_type": -1, "uid": "1251637637"}, {"original_text": "//@王威廉: 还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力", "username": "ZeyuT_T", "province": 44, "statuses_count": 1479, "friends_count": 471, "city": 1, "text": "", "user_description": "", "mid": "3747402298705060", "verified_reason": "", "followers_count": 274, "parent": "3747400319453702", "t": 1408933794, "gender": "m", "verified": false, "verified_type": -1, "uid": "1709747103"}, {"original_text": "//@王威廉:还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？", "username": "Terry右翼的刚烈", "province": 400, "statuses_count": 990, "friends_count": 331, "city": 1, "text": "", "user_description": "既然选择了远方，便只顾风雨兼程", "mid": "3747402374504721", "verified_reason": "", "followers_count": 245, "parent": "3747401624362819", "t": 1408933812, "gender": "m", "verified": false, "verified_type": 220, "uid": "1242677540"}, {"original_text": " //@王威廉:还有一点就是: log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力。[黑线]", "username": "龙星镖局", "province": 11, "statuses_count": 6481, "friends_count": 255, "city": 8, "text": " ", "user_description": "本博立场仅代表个人观点。", "mid": "3747402563559996", "verified_reason": "", "followers_count": 13090, "parent": "3747400319453702", "t": 1408933857, "gender": "m", "verified": false, "verified_type": -1, "uid": "1830516311"}, {"original_text": "//@王威廉:还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？", "username": "荆南迂叟", "province": 100, "statuses_count": 6568, "friends_count": 1348, "city": 1000, "text": "", "user_description": "自别荆南万里游，朱颜渐改鬓将秋。无情最是天边月，犹挂寒空照九州。", "mid": "3747402856646605", "verified_reason": "", "followers_count": 865, "parent": "3747401564834395", "t": 1408933927, "gender": "m", "verified": false, "verified_type": -1, "uid": "1658030270"}, {"original_text": "//@王威廉: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力。[黑线]", "username": "summlux", "province": 11, "statuses_count": 424, "friends_count": 414, "city": 8, "text": "", "user_description": "i was lost", "mid": "3747403054101395", "verified_reason": "", "followers_count": 468, "parent": "3747400319453702", "t": 1408933975, "gender": "m", "verified": false, "verified_type": -1, "uid": "1721470977"}, {"original_text": "还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力。[黑线]", "username": "大头娃娃byrons", "province": 43, "statuses_count": 3146, "friends_count": 165, "city": 1, "text": "还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力。[黑线]", "user_description": "", "mid": "3747403078982959", "verified_reason": "", "followers_count": 91, "parent": "3747400319453702", "t": 1408933980, "gender": "m", "verified": false, "verified_type": -1, "uid": "1911663443"}, {"original_text": "汗，logistics regression本来不就是二元分类吗//@王威廉: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题的baseline。做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？[黑线]", "username": "arcaneorb", "province": 31, "statuses_count": 931, "friends_count": 82, "city": 12, "text": "汗，logistics regression本来不就是二元分类吗", "user_description": "世界一の剣豪になることだ！", "mid": "3747403502680222", "verified_reason": "", "followers_count": 107, "parent": "3747400319453702", "t": 1408934081, "gender": "m", "verified": false, "verified_type": -1, "uid": "2140465727"}, {"original_text": "哟，好想知道是投哪儿的。。。 //@王威廉:还有一点就是: log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力。[黑线]", "username": "CodingCat", "province": 400, "statuses_count": 9020, "friends_count": 500, "city": 5, "text": "哟，好想知道是投哪儿的。。。 ", "user_description": "一只会写代码的猫, 歌神控， 猫咪控", "mid": "3747403573995280", "verified_reason": "", "followers_count": 1377, "parent": "3747402563559996", "t": 1408934098, "gender": "m", "verified": false, "verified_type": -1, "uid": "1891996243"}, {"original_text": "哈哈哈//@龙星计划: //@王威廉:还有一点就是: log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力。[黑线]", "username": "maris205", "province": 42, "statuses_count": 5708, "friends_count": 931, "city": 1, "text": "哈哈哈", "user_description": "搜索&nlp爱好者", "mid": "3747404799192663", "verified_reason": "", "followers_count": 391, "parent": "3747402563559996", "t": 1408934390, "gender": "m", "verified": false, "verified_type": -1, "uid": "1027057001"}, {"original_text": "经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的//@王威廉: 一般来说做回归问题，用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力。[黑线]", "username": "陈天奇怪", "province": 31, "statuses_count": 724, "friends_count": 252, "city": 12, "text": "经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的", "user_description": "想要做研究的coder// http://homes.cs.washington.edu/~tqchen", "mid": "3747405084567580", "verified_reason": "", "followers_count": 11196, "parent": "3747400319453702", "t": 1408934458, "gender": "m", "verified": false, "verified_type": -1, "uid": "2397265244"}, {"original_text": "baseline这个点好//@龙星计划: //@王威廉:还有一点就是: log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力。[黑线]", "username": "Zidane4ever", "province": 11, "statuses_count": 5435, "friends_count": 1481, "city": 5, "text": "baseline这个点好", "user_description": "", "mid": "3747405398308052", "verified_reason": "", "followers_count": 90, "parent": "3747402563559996", "t": 1408934533, "gender": "m", "verified": false, "verified_type": -1, "uid": "1490375892"}, {"original_text": "转一下//@龙星计划: //@王威廉:还有一点就是: log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用lo...", "username": "文阳NOAHARK", "province": 11, "statuses_count": 2051, "friends_count": 216, "city": 5, "text": "转一下", "user_description": "数据挖掘", "mid": "3747407701562624", "verified_reason": "", "followers_count": 335, "parent": "3747402563559996", "t": 1408935081, "gender": "m", "verified": false, "verified_type": -1, "uid": "1775041591"}, {"original_text": "要是想得到比较好的\"confidence score\"或者后验概率的话，logistic regression很好用。//@陈天奇怪:经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的//@王威廉: 一般来说做回归问题，用squared loss的线性回归模型做baseline较常见。", "username": "王威廉", "province": 400, "statuses_count": 2449, "friends_count": 337, "city": 1, "text": "要是想得到比较好的\"confidence score\"或者后验概率的话，logistic regression很好用。", "user_description": "NLP, Machine Learning, and Speech @ CMU http://www.cs.cmu.edu/~yww/", "mid": "3747407898788180", "verified_reason": "", "followers_count": 43783, "parent": "3747405084567580", "t": 1408935128, "gender": "m", "verified": false, "verified_type": -1, "uid": "1657470871"}, {"original_text": "//@王威廉:要是想得到比较好的\"confidence score\"或者后验概率的话，logistic regression很好用。//@陈天奇怪:经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的//一般来说做回归问题，用squared loss的线性回归模型做baseline较常见。", "username": "桥水哒哒哒", "province": 33, "statuses_count": 243, "friends_count": 568, "city": 1, "text": "", "user_description": "反依赖 | 瑜不掩瑕 丨Brony", "mid": "3747408448469985", "verified_reason": "", "followers_count": 450, "parent": "3747407898788180", "t": 1408935261, "gender": "m", "verified": false, "verified_type": -1, "uid": "2173787604"}, {"original_text": "LR根本不是回归方法，而是分类方法。不要因为regression就认为是回归… //@王威廉://@陈天奇怪:经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的//@王威廉: 一般来说做回归问题，用squared loss的线性回归模型做baseline较常见。", "username": "StoicTraveler", "province": 11, "statuses_count": 2667, "friends_count": 153, "city": 2, "text": "LR根本不是回归方法，而是分类方法。不要因为regression就认为是回归… ", "user_description": "一纽约对冲基金Quant，在华外国人，前国際旅行者", "mid": "3747409060041798", "verified_reason": "", "followers_count": 452, "parent": "3747407898788180", "t": 1408935406, "gender": "m", "verified": false, "verified_type": -1, "uid": "2696961873"}, {"original_text": "lr本身就有概率的推导，用到概率应该不错！ //@陈天奇怪:经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的 //@王威廉: 一般来说做回归问题，用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用", "username": "HIT_YangLiu", "province": 23, "statuses_count": 534, "friends_count": 186, "city": 1, "text": "lr本身就有概率的推导，用到概率应该不错！ ", "user_description": "只有你自己才能挽救你！", "mid": "3747410486089330", "verified_reason": "", "followers_count": 137, "parent": "3747405084567580", "t": 1408935746, "gender": "m", "verified": false, "verified_type": -1, "uid": "2739259721"}, {"original_text": "@王威廉: 要是想得到比较好的\"confidence score\"或者后验概率的话，logistic regression很好用@陈天奇怪:经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的@王威廉: 一般来说做回归问题，用squared loss的线性回归模型做baseline较常见", "username": "jianying", "province": 31, "statuses_count": 2577, "friends_count": 465, "city": 13, "text": "@王威廉: 要是想得到比较好的\"confidence score\"或者后验概率的话，logistic regression很好用@陈天奇怪:经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的@王威廉: 一般来说做回归问题，用squared loss的线性回归模型做baseline较常见", "user_description": "提高主动性!", "mid": "3747410780042379", "verified_reason": "", "followers_count": 331, "parent": "3747407898788180", "t": 1408935816, "gender": "f", "verified": false, "verified_type": -1, "uid": "1903598185"}, {"original_text": " //@王威廉:要是想得到比较好的confidence score或者后验概率的话，logistic regression很好用。//@陈天奇怪:经验里面很多回归问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的//@王威廉: 一般来说做回归问题用squared loss的线性回归模型做baseli较常见", "username": "黄浩XJU", "province": 65, "statuses_count": 2081, "friends_count": 347, "city": 1, "text": " ", "user_description": "教书匠、码农、西北民间科学家黄大锤WonderTree https://sites.google.com/site/hwanghao", "mid": "3747410993988441", "verified_reason": "", "followers_count": 377, "parent": "3747407898788180", "t": 1408935866, "gender": "m", "verified": false, "verified_type": -1, "uid": "2166237637"}, {"original_text": "//@陈天奇怪: 经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的//@王威廉: 一般来说做回归问题，用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？[黑线]", "username": "龙星镖局", "province": 11, "statuses_count": 6481, "friends_count": 255, "city": 8, "text": "", "user_description": "本博立场仅代表个人观点。", "mid": "3747411115382046", "verified_reason": "", "followers_count": 13090, "parent": "3747405084567580", "t": 1408935896, "gender": "m", "verified": false, "verified_type": -1, "uid": "1830516311"}, {"original_text": " //@龙星计划: //@王威廉:还有一点就是: log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力。[黑线]", "username": "机器熊sheldon", "province": 100, "statuses_count": 2507, "friends_count": 389, "city": 1000, "text": " ", "user_description": "屈己者能处众，好胜者必遇敌。能言者未必能行，能行者未必能言。贫莫贫于无才，贱莫贱于无志", "mid": "3747412516955216", "verified_reason": "", "followers_count": 85, "parent": "3747402563559996", "t": 1408936229, "gender": "m", "verified": false, "verified_type": -1, "uid": "1951213520"}, {"original_text": "//@陈天奇怪: 经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的//@王威廉: 一般来说做回归问题，用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？[黑线]", "username": "wenxuanliu", "province": 42, "statuses_count": 2242, "friends_count": 313, "city": 1, "text": "", "user_description": "", "mid": "3747412965137817", "verified_reason": "", "followers_count": 194, "parent": "3747411115382046", "t": 1408936337, "gender": "m", "verified": false, "verified_type": -1, "uid": "1818777563"}, {"original_text": "//@王威廉: 要是想得到比较好的\"confidence score\"或者后验概率的话，logistic regression很好用。经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的//@王威廉: 一般来说做回归问题，用squared loss的线性回归模型做baseline较常见。", "username": "emmating12", "province": 11, "statuses_count": 6281, "friends_count": 1039, "city": 1, "text": "", "user_description": "不忘初心，方得始终。", "mid": "3747414026223990", "verified_reason": "", "followers_count": 344, "parent": "3747407898788180", "t": 1408936590, "gender": "f", "verified": false, "verified_type": -1, "uid": "1648660082"}, {"original_text": "\"confidence score\"或者后验概率的话，logistic regression很好用。//@陈天奇怪:经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的//@王威廉: 一般来说做回归问题，用squared loss的线性回归模型做baseline较常见。", "username": "周鸿炜360", "province": 400, "statuses_count": 845, "friends_count": 793, "city": 1, "text": "\"confidence score\"或者后验概率的话，logistic regression很好用。", "user_description": "别问为什么，都是泪", "mid": "3747419873356166", "verified_reason": "", "followers_count": 110, "parent": "3747407898788180", "t": 1408937983, "gender": "m", "verified": false, "verified_type": -1, "uid": "2931865881"}, {"original_text": "因为logistic和0-1损失更像，square loss就差的有点远了。 //@陈天奇怪:经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的 //@王威廉: 一般来说做回归问题，用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做", "username": "张德园", "province": 21, "statuses_count": 3474, "friends_count": 200, "city": 1, "text": "因为logistic和0-1损失更像，square loss就差的有点远了。 ", "user_description": "", "mid": "3747422909775108", "verified_reason": "", "followers_count": 262, "parent": "3747405084567580", "t": 1408938708, "gender": "m", "verified": false, "verified_type": -1, "uid": "1994147141"}, {"original_text": " //@陈天奇怪: 经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的//@王威廉: 一般来说做回归问题，用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？", "username": "Kevin_机器学习_CA", "province": 11, "statuses_count": 5175, "friends_count": 446, "city": 1000, "text": " ", "user_description": "", "mid": "3747423631817816", "verified_reason": "", "followers_count": 1092, "parent": "3747411115382046", "t": 1408938879, "gender": "m", "verified": false, "verified_type": -1, "uid": "2798235231"}, {"original_text": "上次特地查了。 //@Kevin_机器学习_CA: //@陈天奇怪: 经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的//@王威廉: 一般来说做回归问题，用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logi", "username": "汤旭_ShanghaiTech", "province": 31, "statuses_count": 1856, "friends_count": 1319, "city": 4, "text": "上次特地查了。 ", "user_description": "Homepages: takecareofbigboss.github.io，任重道远，踽踽前行！", "mid": "3747424239642928", "verified_reason": "", "followers_count": 1713, "parent": "3747423631817816", "t": 1408939024, "gender": "m", "verified": false, "verified_type": 220, "uid": "1842792965"}, {"original_text": "//@陈天奇怪: 经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的//@王威廉: 一般来说做回归问题，用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？", "username": "WeiHu1918", "province": 33, "statuses_count": 31959, "friends_count": 1875, "city": 1, "text": "", "user_description": "神 爱 世 人 ， 甚 至 将 他 的 独 生 子 赐 给 他 们 ， 叫 一 切 信 他 的 ， 不 至 灭 亡 ， 反 得 永 生 。", "mid": "3747424587538739", "verified_reason": "", "followers_count": 5588, "parent": "3747423631817816", "t": 1408939108, "gender": "m", "verified": false, "verified_type": -1, "uid": "3973508856"}, {"original_text": "转//@raogaoqi:坏名字//@王威廉:还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做ba...", "username": "小诺_Noah", "province": 81, "statuses_count": 6698, "friends_count": 522, "city": 15, "text": "转", "user_description": "爱关注，爱收集，也爱转发；爱IR，爱NLP，更爱机器学习；欢迎Follow！", "mid": "3747433567975415", "verified_reason": "", "followers_count": 1349, "parent": "3747401564834395", "t": 1408941249, "gender": "m", "verified": false, "verified_type": -1, "uid": "2867879661"}, {"original_text": "//@王威廉: 要是想得到比较好的\"confidence score\"或者后验概率的话，logistic regression很好用。//@陈天奇怪:经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的 一般来说做回归问题，用squared loss的线性回归模型做baseline较常见。", "username": "行者行殇", "province": 43, "statuses_count": 11128, "friends_count": 177, "city": 1, "text": "", "user_description": "科研狗", "mid": "3747433978689281", "verified_reason": "", "followers_count": 51, "parent": "3747407898788180", "t": 1408941347, "gender": "m", "verified": false, "verified_type": -1, "uid": "3735078562"}, {"original_text": "转发微博", "username": "人称徐指导", "province": 31, "statuses_count": 970, "friends_count": 120, "city": 15, "text": "转发微博", "user_description": "总得有个时间可以做一件让自己彻底放松的事。。。。。", "mid": "3747437535593441", "verified_reason": "", "followers_count": 109, "parent": "3747400319453702", "t": 1408942194, "gender": "m", "verified": false, "verified_type": -1, "uid": "1931766990"}, {"original_text": "//@王威廉: 还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？", "username": "健忘的狗", "province": 11, "statuses_count": 285, "friends_count": 136, "city": 5, "text": "", "user_description": "", "mid": "3747438172603842", "verified_reason": "", "followers_count": 45, "parent": "3747400319453702", "t": 1408942347, "gender": "f", "verified": false, "verified_type": -1, "uid": "1357985771"}, {"original_text": "//@王威廉: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力。[黑线]", "username": "卓然_立恒", "province": 51, "statuses_count": 2441, "friends_count": 218, "city": 1, "text": "", "user_description": "程序猿，培训老师", "mid": "3747438273283911", "verified_reason": "", "followers_count": 24, "parent": "3747400319453702", "t": 1408942371, "gender": "m", "verified": false, "verified_type": -1, "uid": "1554824652"}, {"original_text": "//@陈天奇怪: 经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的//@王威廉: 一般来说做回归问题，用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？[黑线]", "username": "莅歌", "province": 12, "statuses_count": 767, "friends_count": 311, "city": 4, "text": "", "user_description": "leegle®©™", "mid": "3747453910018552", "verified_reason": "", "followers_count": 119, "parent": "3747411115382046", "t": 1408946099, "gender": "m", "verified": false, "verified_type": -1, "uid": "1659331355"}, {"original_text": "//@王威廉: 还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？", "username": "YinghaoC", "province": 400, "statuses_count": 565, "friends_count": 362, "city": 16, "text": "", "user_description": "", "mid": "3747467806075366", "verified_reason": "", "followers_count": 303, "parent": "3747400319453702", "t": 1408949411, "gender": "f", "verified": false, "verified_type": -1, "uid": "1711291583"}, {"original_text": "中文翻译真的很误导呢//@陈天奇怪:经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的//@王威廉: 一般来说做回归问题，用squared loss的线性回归模型做baseline较常见。", "username": "Kate_落地", "province": 32, "statuses_count": 1958, "friends_count": 285, "city": 2, "text": "中文翻译真的很误导呢", "user_description": "All dots are connected", "mid": "3747485044256909", "verified_reason": "", "followers_count": 531, "parent": "3747407898788180", "t": 1408953521, "gender": "f", "verified": false, "verified_type": -1, "uid": "2074747737"}, {"original_text": "//@王威廉: 还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力", "username": "龙马精神_吴毅", "province": 32, "statuses_count": 8519, "friends_count": 131, "city": 1, "text": "", "user_description": "", "mid": "3747520179675040", "verified_reason": "", "followers_count": 832, "parent": "3747400319453702", "t": 1408961899, "gender": "m", "verified": false, "verified_type": -1, "uid": "3103929783"}, {"original_text": "//@王威廉: 还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力", "username": "hbyido", "province": 33, "statuses_count": 54219, "friends_count": 1403, "city": 1, "text": "", "user_description": "记录时代", "mid": "3747532058397477", "verified_reason": "", "followers_count": 3524, "parent": "3747520179675040", "t": 1408964730, "gender": "m", "verified": false, "verified_type": -1, "uid": "1646706835"}, {"original_text": "//@陈天奇怪:经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的//@王威廉: 一般来说做回归问题，用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力。", "username": "砰砰的小屋", "province": 32, "statuses_count": 22409, "friends_count": 1790, "city": 2, "text": "", "user_description": "", "mid": "3747543433794297", "verified_reason": "", "followers_count": 511, "parent": "3747405084567580", "t": 1408967443, "gender": "f", "verified": false, "verified_type": -1, "uid": "2036923815"}, {"original_text": "对率回归[思考] //@王威廉:要是想得到比较好的\"confidence score\"或者后验概率的话，logistic regression很好用。//@陈天奇怪:经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的//@王威廉: 一般来说做回归问题，用squared loss", "username": "ralf阿叉叉", "province": 44, "statuses_count": 11020, "friends_count": 155, "city": 3, "text": "对率回归[思考] ", "user_description": "sz it ds", "mid": "3747558817952813", "verified_reason": "", "followers_count": 120, "parent": "3747407898788180", "t": 1408971111, "gender": "m", "verified": false, "verified_type": -1, "uid": "1892025057"}, {"original_text": "//@王威廉: 还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力", "username": "GreatWindy", "province": 34, "statuses_count": 595, "friends_count": 160, "city": 1, "text": "", "user_description": "", "mid": "3747576895164512", "verified_reason": "", "followers_count": 37, "parent": "3747400319453702", "t": 1408975421, "gender": "m", "verified": false, "verified_type": -1, "uid": "1258979155"}, {"original_text": " //@王威廉:还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？", "username": "冯骁骋HIT", "province": 23, "statuses_count": 330, "friends_count": 181, "city": 1, "text": " ", "user_description": "", "mid": "3747583643727849", "verified_reason": "", "followers_count": 182, "parent": "3747400319453702", "t": 1408977029, "gender": "m", "verified": false, "verified_type": 220, "uid": "2753470833"}, {"original_text": " /@陈天奇怪: 经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的//@王威廉: 一般来说做回归问题，用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？[黑线]", "username": "Noodles-Xu", "province": 31, "statuses_count": 30069, "friends_count": 286, "city": 15, "text": " /@陈天奇怪: 经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的", "user_description": "成功才快乐", "mid": "3747593534505565", "verified_reason": "", "followers_count": 591, "parent": "3747411115382046", "t": 1408979387, "gender": "m", "verified": false, "verified_type": -1, "uid": "1908599781"}, {"original_text": " //@龙星计划: //@王威廉:还有一点就是: log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力。[黑线]", "username": "Noodles-Xu", "province": 31, "statuses_count": 30069, "friends_count": 286, "city": 15, "text": " ", "user_description": "成功才快乐", "mid": "3747593824236119", "verified_reason": "", "followers_count": 591, "parent": "3747402563559996", "t": 1408979457, "gender": "m", "verified": false, "verified_type": -1, "uid": "1908599781"}, {"original_text": "//@ZDr_0: //@王威廉: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力。", "username": "顺其自然QZZ", "province": 12, "statuses_count": 7045, "friends_count": 766, "city": 6, "text": "", "user_description": "", "mid": "3747612710276008", "verified_reason": "", "followers_count": 415, "parent": "3747403054101395", "t": 1408983960, "gender": "m", "verified": false, "verified_type": 220, "uid": "1899530355"}, {"original_text": "//@王威廉: 要是想得到比较好的\"confidence score\"或者后验概率的话，logistic regression很好用。//@王威廉: 一般来说做回归问题，用squared loss的线性回归模型做baseline较常见。", "username": "川门子", "province": 32, "statuses_count": 15, "friends_count": 120, "city": 1, "text": "", "user_description": "", "mid": "3747725533627014", "verified_reason": "", "followers_count": 4, "parent": "3747407898788180", "t": 1409010858, "gender": "m", "verified": false, "verified_type": -1, "uid": "3904885898"}, {"original_text": "//@王威廉: 还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？", "username": "川门子", "province": 32, "statuses_count": 15, "friends_count": 120, "city": 1, "text": "", "user_description": "", "mid": "3747725672071601", "verified_reason": "", "followers_count": 4, "parent": "3747400319453702", "t": 1409010892, "gender": "m", "verified": false, "verified_type": -1, "uid": "3904885898"}, {"original_text": "要是想得到比较好的\"confidence score\"或者后验概率的话，logistic regression很好用。//@陈天奇怪:经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的//@王威廉: 一般来说做回归问题，用squared loss的线性回归模型做baseline较常见。", "username": "倦鸟的家", "province": 31, "statuses_count": 5226, "friends_count": 500, "city": 1000, "text": "要是想得到比较好的\"confidence score\"或者后验概率的话，logistic regression很好用。", "user_description": "我想要有更多的时间，从容的按照自己的方式成长成为“我”，从而有一天更有勇气拒绝成为“他们”。", "mid": "3747771327127817", "verified_reason": "", "followers_count": 1024, "parent": "3747407898788180", "t": 1409021777, "gender": "f", "verified": false, "verified_type": -1, "uid": "1774834931"}, {"original_text": "还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力。[黑线]", "username": "Kipy", "province": 81, "statuses_count": 503, "friends_count": 200, "city": 7, "text": "还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力。[黑线]", "user_description": "", "mid": "3756715365784825", "verified_reason": "", "followers_count": 117, "parent": "3747400319453702", "t": 1411154201, "gender": "m", "verified": false, "verified_type": -1, "uid": "1701081555"}]