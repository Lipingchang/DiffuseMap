[{"original_text": "//@是农工熵: 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli版本的，估算概率的理论依据，朴素贝叶斯、决策树等太多地方使用了。", "username": "爱可可-爱生活", "province": 11, "statuses_count": 12394, "friends_count": 1272, "city": 5, "text": "", "user_description": "北邮网络搜索中心老师", "mid": "3827499957763040", "verified_reason": "微博知名互联网帐号 微博签约自媒体", "followers_count": 28908, "parent": "", "t": 1428030564, "gender": "m", "verified": true, "verified_type": 0, "uid": "1402400261"}, {"original_text": " //@爱可可-爱生活://@是农工熵: 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli版本的，估算概率的理论依据，朴素贝叶斯、决策树等太多地方", "username": "Great_Brave", "province": 400, "statuses_count": 884, "friends_count": 394, "city": 1, "text": " ", "user_description": "快乐的小飞侠，永不停歇的脚步，只为学以致用，思以创新，乐以生活。", "mid": "3827501245758930", "verified_reason": "", "followers_count": 77, "parent": "3827499957763040", "t": 1428030871, "gender": "m", "verified": false, "verified_type": -1, "uid": "1656277871"}, {"original_text": "邹博在@七月问答 也有专栏！ http://t.cn/RAc8Z0Y @研究者July //@爱可可-爱生活: //@是农工熵: 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli", "username": "BigData大数据", "province": 100, "statuses_count": 6933, "friends_count": 506, "city": 1000, "text": "邹博在@七月问答 也有专栏！ http://t.cn/RAc8Z0Y @研究者July ", "user_description": "博士，曾任职网易高级研究员和惠普云计算专家，大数据和深度学习研究者，CCF高级会员，CCF大数据专委会委员， 本微博所发表言论与任何单位无关！", "mid": "3827502462317907", "verified_reason": "网易 在线游戏事业部高级研究员", "followers_count": 17233, "parent": "3827499957763040", "t": 1428031160, "gender": "m", "verified": true, "verified_type": 0, "uid": "2870219257"}, {"original_text": "//@BigData大数据:邹博在@七月问答 也有专栏！ http://t.cn/RAc8Z0Y @研究者July //@爱可可-爱生活: //@是农工熵: 赞！", "username": "General_Chai", "province": 12, "statuses_count": 566, "friends_count": 282, "city": 1, "text": "", "user_description": "副业数据挖掘，机器学习，云计算，专职帮室友表白，NUDT在读", "mid": "3827502927097361", "verified_reason": "", "followers_count": 110, "parent": "3827502462317907", "t": 1428031272, "gender": "m", "verified": false, "verified_type": -1, "uid": "2610174151"}, {"original_text": " //@爱可可-爱生活://@是农工熵: 也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli版本的，估算概率的理论依据，朴素贝叶斯、决策树等太多地方使用了。", "username": "CS_MZ", "province": 11, "statuses_count": 540, "friends_count": 210, "city": 8, "text": " ", "user_description": "computer science", "mid": "3827503829101978", "verified_reason": "", "followers_count": 37, "parent": "3827499957763040", "t": 1428031487, "gender": "m", "verified": false, "verified_type": -1, "uid": "2011767451"}, {"original_text": "//@BigData大数据:邹博在@七月问答 也有专栏！ http://t.cn/RAc8Z0Y//@是农工熵: 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli", "username": "风竹2013", "province": 11, "statuses_count": 1554, "friends_count": 143, "city": 14, "text": "", "user_description": "", "mid": "3827504017703518", "verified_reason": "", "followers_count": 36, "parent": "3827502462317907", "t": 1428031532, "gender": "f", "verified": false, "verified_type": -1, "uid": "2272490237"}, {"original_text": "@是农工熵: 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli版本的，估算概率的理论依据，朴素贝叶斯、决策树等太多地方使用了。", "username": "大头娃娃byrons", "province": 43, "statuses_count": 3139, "friends_count": 165, "city": 1, "text": "@是农工熵: 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli版本的，估算概率的理论依据，朴素贝叶斯、决策树等太多地方使用了。", "user_description": "", "mid": "3827507906354121", "verified_reason": "", "followers_count": 91, "parent": "3827499957763040", "t": 1428032459, "gender": "m", "verified": false, "verified_type": -1, "uid": "1911663443"}, {"original_text": " 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli", "username": "NeilNJU", "province": 32, "statuses_count": 558, "friends_count": 729, "city": 1, "text": " 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli", "user_description": "NJU", "mid": "3827508598446165", "verified_reason": "", "followers_count": 59, "parent": "3827502462317907", "t": 1428032624, "gender": "m", "verified": false, "verified_type": -1, "uid": "3043326901"}, {"original_text": "@有道云笔记收藏 也有专栏！ http://t.cn/RAc8Z0Y 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli", "username": "RoughGush", "province": 35, "statuses_count": 5900, "friends_count": 559, "city": 2, "text": "@有道云笔记收藏 也有专栏！ http://t.cn/RAc8Z0Y 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli", "user_description": "境由心造，苦乐由我；韬光养晦，允厥执中。", "mid": "3827519348622227", "verified_reason": "", "followers_count": 155, "parent": "3827502462317907", "t": 1428035187, "gender": "m", "verified": false, "verified_type": -1, "uid": "1400821954"}, {"original_text": " http://t.cn/RAc8Z0Y @研究者July //@爱可可-爱生活: //@是农工熵: 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli", "username": "蓝色幽灵110", "province": 35, "statuses_count": 1538, "friends_count": 248, "city": 5, "text": " http://t.cn/RAc8Z0Y @研究者July ", "user_description": "年轻是我的资本，宁可追求虚无，也不可无所追求。", "mid": "3827519885213833", "verified_reason": "", "followers_count": 112, "parent": "3827502462317907", "t": 1428035315, "gender": "m", "verified": false, "verified_type": -1, "uid": "2022980387"}, {"original_text": ":邹博在@七月问答 也有专栏！ http://t.cn/RAc8Z0Y @研究者July //@爱可可-爱生活: //@是农工熵: 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli", "username": "小虫-called-小五", "province": 32, "statuses_count": 2720, "friends_count": 1056, "city": 3, "text": ":邹博在@七月问答 也有专栏！ http://t.cn/RAc8Z0Y @研究者July ", "user_description": "一只向两极爬的小虫", "mid": "3827520308388732", "verified_reason": "", "followers_count": 281, "parent": "3827502462317907", "t": 1428035416, "gender": "m", "verified": false, "verified_type": -1, "uid": "2795909382"}, {"original_text": "是农工熵: 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli版本的，估算概率的理论依据，朴素贝叶斯、决策树等太多地方使用了。", "username": "huahuacyh", "province": 41, "statuses_count": 3335, "friends_count": 56, "city": 8, "text": "是农工熵: 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli版本的，估算概率的理论依据，朴素贝叶斯、决策树等太多地方使用了。", "user_description": "", "mid": "3827521516910898", "verified_reason": "", "followers_count": 23, "parent": "3827499957763040", "t": 1428035703, "gender": "f", "verified": false, "verified_type": -1, "uid": "1423057525"}, {"original_text": "//@BigData大数据:邹博在@七月问答 也有专栏！ http://t.cn/RAc//@爱可可-爱生活: //@是农工熵: 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli", "username": "Candy的爸爸", "province": 44, "statuses_count": 2610, "friends_count": 575, "city": 1, "text": "", "user_description": "", "mid": "3827522851005271", "verified_reason": "", "followers_count": 76, "parent": "3827502462317907", "t": 1428036022, "gender": "m", "verified": false, "verified_type": -1, "uid": "1414577374"}, {"original_text": " //@爱可可-爱生活://@是农工熵: 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli版本的，估算概率", "username": "喵星的汪", "province": 43, "statuses_count": 1471, "friends_count": 64, "city": 1, "text": " ", "user_description": "", "mid": "3827526902635624", "verified_reason": "", "followers_count": 11, "parent": "3827499957763040", "t": 1428036987, "gender": "m", "verified": false, "verified_type": -1, "uid": "1815237617"}, {"original_text": "//@爱可可-爱生活: //@是农工熵: 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli版本的，估算概率的理论依据，朴素贝叶斯、决策树等太多地方使用", "username": "路确实脚下", "province": 61, "statuses_count": 2009, "friends_count": 323, "city": 1, "text": "", "user_description": "君子思不出其位。 君子耻其言而过其行。 邦有道，危言危行；邦无道，危行言孙。———《论语·宪问》", "mid": "3827531776451458", "verified_reason": "", "followers_count": 185, "parent": "3827499957763040", "t": 1428038150, "gender": "m", "verified": false, "verified_type": -1, "uid": "1912305871"}, {"original_text": "@七月问答 也有专栏！ http://t.cn/RAc8Z0Y @研究者July //@爱可可-爱生活: //@是农工熵: 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli", "username": "李鸢gasover", "province": 50, "statuses_count": 31406, "friends_count": 1965, "city": 7, "text": "@七月问答 也有专栏！ http://t.cn/RAc8Z0Y @研究者July ", "user_description": "心如工画师，能画诸世间。五蕴悉从生，无法而不造。", "mid": "3827534477587254", "verified_reason": "", "followers_count": 411, "parent": "3827502462317907", "t": 1428038794, "gender": "m", "verified": false, "verified_type": -1, "uid": "1742011211"}, {"original_text": "//@是农工熵: 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli版本的，估算概率的理论依据，朴素贝叶斯、决策树等太多地方使用了。", "username": "红雨箫浪", "province": 32, "statuses_count": 1298, "friends_count": 330, "city": 1, "text": "", "user_description": "梦想起航，相信自己！", "mid": "3827536599881739", "verified_reason": "", "followers_count": 79, "parent": "3827499957763040", "t": 1428039300, "gender": "m", "verified": false, "verified_type": -1, "uid": "1811520005"}, {"original_text": "//@爱可可-爱生活: //@是农工熵: 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli版本的，估算概率的理论依据，朴素贝叶斯、决策树等太多地方", "username": "桑榆Leo", "province": 11, "statuses_count": 906, "friends_count": 456, "city": 8, "text": "", "user_description": "桑榆非晚，老牛要吃学术和生活的嫩草。", "mid": "3827550147299776", "verified_reason": "", "followers_count": 96, "parent": "3827499957763040", "t": 1428042530, "gender": "m", "verified": false, "verified_type": -1, "uid": "3170435515"}, {"original_text": "mark //@BigData大数据:邹博在@七月问答 也有专栏！ http://t.cn/RAc8Z0Y @研究者July //@爱可可-爱生活: //@是农工熵: 赞！机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli", "username": "Rec_Jimmy", "province": 100, "statuses_count": 157, "friends_count": 164, "city": 1000, "text": "mark ", "user_description": "勿欺人，勿欺己", "mid": "3827608255320985", "verified_reason": "", "followers_count": 52, "parent": "3827502462317907", "t": 1428056383, "gender": "m", "verified": false, "verified_type": -1, "uid": "2359525332"}, {"original_text": "//@爱可可-爱生活://@是农工熵: 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli版本的，估算概率的理论依据，朴素贝叶斯、决策树等太多地方使用了", "username": "海边的星空海边的森林", "province": 61, "statuses_count": 2159, "friends_count": 96, "city": 1, "text": "", "user_description": "", "mid": "3827631835652582", "verified_reason": "", "followers_count": 65, "parent": "3827499957763040", "t": 1428062005, "gender": "m", "verified": false, "verified_type": -1, "uid": "1901399451"}, {"original_text": " /可可-爱生活://@是农工熵: 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli版本的，估算概率的理论依据，朴素贝叶斯、决策树等太多地方使用了。", "username": "Noodles-Xu", "province": 31, "statuses_count": 29969, "friends_count": 286, "city": 15, "text": " /可可-爱生活:", "user_description": "成功才快乐", "mid": "3827642988384254", "verified_reason": "", "followers_count": 590, "parent": "3827499957763040", "t": 1428064665, "gender": "m", "verified": false, "verified_type": -1, "uid": "1908599781"}, {"original_text": "//@爱可可-爱生活: //@是农工熵: 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli版本的，估算概率的理论依据，朴素贝叶斯、决策树等太多地方使用", "username": "数据分析小白", "province": 51, "statuses_count": 1136, "friends_count": 374, "city": 1, "text": "", "user_description": "学生的干活", "mid": "3827646398109100", "verified_reason": "", "followers_count": 72, "parent": "3827499957763040", "t": 1428065478, "gender": "m", "verified": false, "verified_type": -1, "uid": "1368512363"}, {"original_text": "://@是农工熵: 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli版本的，估算概率的理论依据，朴素贝叶斯、决策树等太多地方使用了。", "username": "ycp107被抢注", "province": 32, "statuses_count": 1145, "friends_count": 171, "city": 1, "text": ":", "user_description": "龙腾虎跃", "mid": "3827648369529841", "verified_reason": "", "followers_count": 82, "parent": "3827499957763040", "t": 1428065948, "gender": "m", "verified": false, "verified_type": -1, "uid": "2511504650"}, {"original_text": "//@BigData大数据:邹博在@七月问答 也有专栏！ http://t.cn/RAc8Z0Y @研究者July //@爱可可-爱生活: //@是农工熵: 赞！机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli", "username": "陈月二四六七八", "province": 33, "statuses_count": 457, "friends_count": 560, "city": 1000, "text": "", "user_description": "一定要好好搞学术。", "mid": "3827686491383600", "verified_reason": "", "followers_count": 69, "parent": "3827608255320985", "t": 1428075037, "gender": "m", "verified": false, "verified_type": -1, "uid": "3203359640"}, {"original_text": "//@爱可可-爱生活: //@是农工熵: 赞！整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli版本的，估算概率的理论依据，朴素贝叶斯、决策树等太多地方使用了。", "username": "FantasticJuly", "province": 44, "statuses_count": 6191, "friends_count": 1244, "city": 1, "text": "", "user_description": "", "mid": "3828207537326351", "verified_reason": "", "followers_count": 74, "parent": "3827499957763040", "t": 1428199264, "gender": "m", "verified": false, "verified_type": -1, "uid": "2155937240"}, {"original_text": "@七月问答 也有专栏！ http://t.cn/RAc8Z0Y @研究者July //@爱可可-爱生活: //@是农工熵: 赞！也说缺点吧。整体略简单了。机器学习方向的基础，应该增加特征向量、正交：线性回归、谱聚类、PCA等都要用。概率论中没谈中心极限定理，在线性回归的目标函数时马上会用；大数定理，尤其是Bernoulli", "username": "dp117", "province": 31, "statuses_count": 246, "friends_count": 252, "city": 10, "text": "@七月问答 也有专栏！ http://t.cn/RAc8Z0Y @研究者July ", "user_description": "linux内核 分布式系统", "mid": "3828228257109427", "verified_reason": "", "followers_count": 59, "parent": "3827502462317907", "t": 1428204204, "gender": "m", "verified": false, "verified_type": -1, "uid": "2871158472"}]