{"original_text": "还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力。[黑线]", "evtlist": [539], "uid": "1657470871", "dep": 0, "text": "还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力。[黑线]", "pid": "", "tr": 55, "mid": "3747400319453702", "times": 1, "childnum": 22, "t": 1408933322, "totalChildren": 55, "dr": 22, "children": [{"evtlist": [539], "uid": "1653959761", "dep": 0, "text": "", "pid": "3747400319453702", "tr": 0, "mid": "3747400843288162", "times": 1, "childnum": 0, "t": 1408933447, "totalChildren": 0, "dr": 0, "children": [], "name": "icecile"}, {"evtlist": [539], "uid": "3973508856", "dep": 0, "text": "", "pid": "3747400319453702", "tr": 0, "mid": "3747401216647114", "times": 1, "childnum": 0, "t": 1408933536, "totalChildren": 0, "dr": 0, "children": [], "name": "WeiHu1918"}, {"evtlist": [539], "uid": "1240989305", "dep": 0, "text": "", "pid": "3747400319453702", "tr": 0, "mid": "3747401325717071", "times": 1, "childnum": 0, "t": 1408933562, "totalChildren": 0, "dr": 0, "children": [], "name": "THB-HEU"}, {"evtlist": [539], "uid": "1242190153", "dep": 0, "text": "坏名字", "pid": "3747400319453702", "tr": 2, "mid": "3747401564834395", "times": 1, "childnum": 2, "t": 1408933619, "totalChildren": 2, "dr": 2, "children": [{"evtlist": [539], "uid": "1658030270", "dep": 0, "text": "", "pid": "3747401564834395", "tr": 0, "mid": "3747402856646605", "times": 1, "childnum": 0, "t": 1408933927, "totalChildren": 0, "dr": 0, "children": [], "name": "荆南迂叟"}, {"evtlist": [539], "uid": "2867879661", "dep": 0, "text": "转", "pid": "3747401564834395", "tr": 0, "mid": "3747433567975415", "times": 1, "childnum": 0, "t": 1408941249, "totalChildren": 0, "dr": 0, "children": [], "name": "小诺_Noah"}], "name": "raogaoqi"}, {"evtlist": [539], "uid": "1218274631", "dep": 0, "text": "这也是常见错误 ", "pid": "3747400319453702", "tr": 1, "mid": "3747401624362819", "times": 1, "childnum": 1, "t": 1408933633, "totalChildren": 1, "dr": 1, "children": [{"evtlist": [539], "uid": "1242677540", "dep": 0, "text": "", "pid": "3747401624362819", "tr": 0, "mid": "3747402374504721", "times": 1, "childnum": 0, "t": 1408933812, "totalChildren": 0, "dr": 0, "children": [], "name": "Terry右翼的刚烈"}], "name": "winsty"}, {"evtlist": [539], "uid": "3041845821", "dep": 0, "text": "转发微博", "pid": "3747400319453702", "tr": 0, "mid": "3747401686778854", "times": 1, "childnum": 0, "t": 1408933648, "totalChildren": 0, "dr": 0, "children": [], "name": "kilkennypaopao"}, {"evtlist": [539], "uid": "1251637637", "dep": 0, "text": "", "pid": "3747400319453702", "tr": 0, "mid": "3747402060516397", "times": 1, "childnum": 0, "t": 1408933737, "totalChildren": 0, "dr": 0, "children": [], "name": "朱凌凌00"}, {"evtlist": [539], "uid": "1709747103", "dep": 0, "text": "", "pid": "3747400319453702", "tr": 0, "mid": "3747402298705060", "times": 1, "childnum": 0, "t": 1408933794, "totalChildren": 0, "dr": 0, "children": [], "name": "ZeyuT_T"}, {"evtlist": [539], "uid": "1830516311", "dep": 0, "text": " ", "pid": "3747400319453702", "tr": 6, "mid": "3747402563559996", "times": 1, "childnum": 6, "t": 1408933857, "totalChildren": 6, "dr": 6, "children": [{"evtlist": [539], "uid": "1891996243", "dep": 0, "text": "哟，好想知道是投哪儿的。。。 ", "pid": "3747402563559996", "tr": 0, "mid": "3747403573995280", "times": 1, "childnum": 0, "t": 1408934098, "totalChildren": 0, "dr": 0, "children": [], "name": "CodingCat"}, {"evtlist": [539], "uid": "1027057001", "dep": 0, "text": "哈哈哈", "pid": "3747402563559996", "tr": 0, "mid": "3747404799192663", "times": 1, "childnum": 0, "t": 1408934390, "totalChildren": 0, "dr": 0, "children": [], "name": "maris205"}, {"evtlist": [539], "uid": "1490375892", "dep": 0, "text": "baseline这个点好", "pid": "3747402563559996", "tr": 0, "mid": "3747405398308052", "times": 1, "childnum": 0, "t": 1408934533, "totalChildren": 0, "dr": 0, "children": [], "name": "Zidane4ever"}, {"evtlist": [539], "uid": "1775041591", "dep": 0, "text": "转一下", "pid": "3747402563559996", "tr": 0, "mid": "3747407701562624", "times": 1, "childnum": 0, "t": 1408935081, "totalChildren": 0, "dr": 0, "children": [], "name": "文阳NOAHARK"}, {"evtlist": [539], "uid": "1951213520", "dep": 0, "text": " ", "pid": "3747402563559996", "tr": 0, "mid": "3747412516955216", "times": 1, "childnum": 0, "t": 1408936229, "totalChildren": 0, "dr": 0, "children": [], "name": "机器熊sheldon"}, {"evtlist": [539], "uid": "1908599781", "dep": 0, "text": " ", "pid": "3747402563559996", "tr": 0, "mid": "3747593824236119", "times": 1, "childnum": 0, "t": 1408979457, "totalChildren": 0, "dr": 0, "children": [], "name": "Noodles-Xu"}], "name": "龙星镖局"}, {"evtlist": [539], "uid": "1721470977", "dep": 0, "text": "", "pid": "3747400319453702", "tr": 1, "mid": "3747403054101395", "times": 1, "childnum": 1, "t": 1408933975, "totalChildren": 1, "dr": 1, "children": [{"evtlist": [539], "uid": "1899530355", "dep": 0, "text": "", "pid": "3747403054101395", "tr": 0, "mid": "3747612710276008", "times": 1, "childnum": 0, "t": 1408983960, "totalChildren": 0, "dr": 0, "children": [], "name": "顺其自然QZZ"}], "name": "summlux"}, {"evtlist": [539], "uid": "1911663443", "dep": 0, "text": "还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力。[黑线]", "pid": "3747400319453702", "tr": 0, "mid": "3747403078982959", "times": 1, "childnum": 0, "t": 1408933980, "totalChildren": 0, "dr": 0, "children": [], "name": "大头娃娃byrons"}, {"evtlist": [539], "uid": "2140465727", "dep": 0, "text": "汗，logistics regression本来不就是二元分类吗", "pid": "3747400319453702", "tr": 0, "mid": "3747403502680222", "times": 1, "childnum": 0, "t": 1408934081, "totalChildren": 0, "dr": 0, "children": [], "name": "arcaneorb"}, {"evtlist": [539], "uid": "2397265244", "dep": 0, "text": "经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的", "pid": "3747400319453702", "tr": 22, "mid": "3747405084567580", "times": 1, "childnum": 5, "t": 1408934458, "totalChildren": 22, "dr": 5, "children": [{"evtlist": [539], "uid": "1657470871", "dep": 0, "text": "要是想得到比较好的\"confidence score\"或者后验概率的话，logistic regression很好用。", "pid": "3747405084567580", "tr": 11, "mid": "3747407898788180", "times": 1, "childnum": 11, "t": 1408935128, "totalChildren": 11, "dr": 11, "children": [{"evtlist": [539], "uid": "2173787604", "dep": 0, "text": "", "pid": "3747407898788180", "tr": 0, "mid": "3747408448469985", "times": 1, "childnum": 0, "t": 1408935261, "totalChildren": 0, "dr": 0, "children": [], "name": "桥水哒哒哒"}, {"evtlist": [539], "uid": "2696961873", "dep": 0, "text": "LR根本不是回归方法，而是分类方法。不要因为regression就认为是回归… ", "pid": "3747407898788180", "tr": 0, "mid": "3747409060041798", "times": 1, "childnum": 0, "t": 1408935406, "totalChildren": 0, "dr": 0, "children": [], "name": "StoicTraveler"}, {"evtlist": [539], "uid": "1903598185", "dep": 0, "text": "@王威廉: 要是想得到比较好的\"confidence score\"或者后验概率的话，logistic regression很好用@陈天奇怪:经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的@王威廉: 一般来说做回归问题，用squared loss的线性回归模型做baseline较常见", "pid": "3747407898788180", "tr": 0, "mid": "3747410780042379", "times": 1, "childnum": 0, "t": 1408935816, "totalChildren": 0, "dr": 0, "children": [], "name": "jianying"}, {"evtlist": [539], "uid": "2166237637", "dep": 0, "text": " ", "pid": "3747407898788180", "tr": 0, "mid": "3747410993988441", "times": 1, "childnum": 0, "t": 1408935866, "totalChildren": 0, "dr": 0, "children": [], "name": "黄浩XJU"}, {"evtlist": [539], "uid": "1648660082", "dep": 0, "text": "", "pid": "3747407898788180", "tr": 0, "mid": "3747414026223990", "times": 1, "childnum": 0, "t": 1408936590, "totalChildren": 0, "dr": 0, "children": [], "name": "emmating12"}, {"evtlist": [539], "uid": "2931865881", "dep": 0, "text": "\"confidence score\"或者后验概率的话，logistic regression很好用。", "pid": "3747407898788180", "tr": 0, "mid": "3747419873356166", "times": 1, "childnum": 0, "t": 1408937983, "totalChildren": 0, "dr": 0, "children": [], "name": "周鸿炜360"}, {"evtlist": [539], "uid": "3735078562", "dep": 0, "text": "", "pid": "3747407898788180", "tr": 0, "mid": "3747433978689281", "times": 1, "childnum": 0, "t": 1408941347, "totalChildren": 0, "dr": 0, "children": [], "name": "行者行殇"}, {"evtlist": [539], "uid": "2074747737", "dep": 0, "text": "中文翻译真的很误导呢", "pid": "3747407898788180", "tr": 0, "mid": "3747485044256909", "times": 1, "childnum": 0, "t": 1408953521, "totalChildren": 0, "dr": 0, "children": [], "name": "Kate_落地"}, {"evtlist": [539], "uid": "1892025057", "dep": 0, "text": "对率回归[思考] ", "pid": "3747407898788180", "tr": 0, "mid": "3747558817952813", "times": 1, "childnum": 0, "t": 1408971111, "totalChildren": 0, "dr": 0, "children": [], "name": "ralf阿叉叉"}, {"evtlist": [539], "uid": "3904885898", "dep": 0, "text": "", "pid": "3747407898788180", "tr": 0, "mid": "3747725533627014", "times": 1, "childnum": 0, "t": 1409010858, "totalChildren": 0, "dr": 0, "children": [], "name": "川门子"}, {"evtlist": [539], "uid": "1774834931", "dep": 0, "text": "要是想得到比较好的\"confidence score\"或者后验概率的话，logistic regression很好用。", "pid": "3747407898788180", "tr": 0, "mid": "3747771327127817", "times": 1, "childnum": 0, "t": 1409021777, "totalChildren": 0, "dr": 0, "children": [], "name": "倦鸟的家"}], "name": "王威廉"}, {"evtlist": [539], "uid": "2739259721", "dep": 0, "text": "lr本身就有概率的推导，用到概率应该不错！ ", "pid": "3747405084567580", "tr": 0, "mid": "3747410486089330", "times": 1, "childnum": 0, "t": 1408935746, "totalChildren": 0, "dr": 0, "children": [], "name": "HIT_YangLiu"}, {"evtlist": [539], "uid": "1830516311", "dep": 0, "text": "", "pid": "3747405084567580", "tr": 6, "mid": "3747411115382046", "times": 1, "childnum": 4, "t": 1408935896, "totalChildren": 6, "dr": 4, "children": [{"evtlist": [539], "uid": "1818777563", "dep": 0, "text": "", "pid": "3747411115382046", "tr": 0, "mid": "3747412965137817", "times": 1, "childnum": 0, "t": 1408936337, "totalChildren": 0, "dr": 0, "children": [], "name": "wenxuanliu"}, {"evtlist": [539], "uid": "2798235231", "dep": 0, "text": " ", "pid": "3747411115382046", "tr": 2, "mid": "3747423631817816", "times": 1, "childnum": 2, "t": 1408938879, "totalChildren": 2, "dr": 2, "children": [{"evtlist": [539], "uid": "1842792965", "dep": 0, "text": "上次特地查了。 ", "pid": "3747423631817816", "tr": 0, "mid": "3747424239642928", "times": 1, "childnum": 0, "t": 1408939024, "totalChildren": 0, "dr": 0, "children": [], "name": "汤旭_ShanghaiTech"}, {"evtlist": [539], "uid": "3973508856", "dep": 0, "text": "", "pid": "3747423631817816", "tr": 0, "mid": "3747424587538739", "times": 1, "childnum": 0, "t": 1408939108, "totalChildren": 0, "dr": 0, "children": [], "name": "WeiHu1918"}], "name": "Kevin_机器学习_CA"}, {"evtlist": [539], "uid": "1659331355", "dep": 0, "text": "", "pid": "3747411115382046", "tr": 0, "mid": "3747453910018552", "times": 1, "childnum": 0, "t": 1408946099, "totalChildren": 0, "dr": 0, "children": [], "name": "莅歌"}, {"evtlist": [539], "uid": "1908599781", "dep": 0, "text": " /@陈天奇怪: 经验里面很多\"回归\"问题scale到0-1用logistic一般都会比square loss好。可以认为logistic用来做概率值回归还是很好的", "pid": "3747411115382046", "tr": 0, "mid": "3747593534505565", "times": 1, "childnum": 0, "t": 1408979387, "totalChildren": 0, "dr": 0, "children": [], "name": "Noodles-Xu"}], "name": "龙星镖局"}, {"evtlist": [539], "uid": "1994147141", "dep": 0, "text": "因为logistic和0-1损失更像，square loss就差的有点远了。 ", "pid": "3747405084567580", "tr": 0, "mid": "3747422909775108", "times": 1, "childnum": 0, "t": 1408938708, "totalChildren": 0, "dr": 0, "children": [], "name": "张德园"}, {"evtlist": [539], "uid": "2036923815", "dep": 0, "text": "", "pid": "3747405084567580", "tr": 0, "mid": "3747543433794297", "times": 1, "childnum": 0, "t": 1408967443, "totalChildren": 0, "dr": 0, "children": [], "name": "砰砰的小屋"}], "name": "陈天奇怪"}, {"evtlist": [539], "uid": "1931766990", "dep": 0, "text": "转发微博", "pid": "3747400319453702", "tr": 0, "mid": "3747437535593441", "times": 1, "childnum": 0, "t": 1408942194, "totalChildren": 0, "dr": 0, "children": [], "name": "人称徐指导"}, {"evtlist": [539], "uid": "1357985771", "dep": 0, "text": "", "pid": "3747400319453702", "tr": 0, "mid": "3747438172603842", "times": 1, "childnum": 0, "t": 1408942347, "totalChildren": 0, "dr": 0, "children": [], "name": "健忘的狗"}, {"evtlist": [539], "uid": "1554824652", "dep": 0, "text": "", "pid": "3747400319453702", "tr": 0, "mid": "3747438273283911", "times": 1, "childnum": 0, "t": 1408942371, "totalChildren": 0, "dr": 0, "children": [], "name": "卓然_立恒"}, {"evtlist": [539], "uid": "1711291583", "dep": 0, "text": "", "pid": "3747400319453702", "tr": 0, "mid": "3747467806075366", "times": 1, "childnum": 0, "t": 1408949411, "totalChildren": 0, "dr": 0, "children": [], "name": "YinghaoC"}, {"evtlist": [539], "uid": "3103929783", "dep": 0, "text": "", "pid": "3747400319453702", "tr": 1, "mid": "3747520179675040", "times": 1, "childnum": 1, "t": 1408961899, "totalChildren": 1, "dr": 1, "children": [{"evtlist": [539], "uid": "1646706835", "dep": 0, "text": "", "pid": "3747520179675040", "tr": 0, "mid": "3747532058397477", "times": 1, "childnum": 0, "t": 1408964730, "totalChildren": 0, "dr": 0, "children": [], "name": "hbyido"}], "name": "龙马精神_吴毅"}, {"evtlist": [539], "uid": "1258979155", "dep": 0, "text": "", "pid": "3747400319453702", "tr": 0, "mid": "3747576895164512", "times": 1, "childnum": 0, "t": 1408975421, "totalChildren": 0, "dr": 0, "children": [], "name": "GreatWindy"}, {"evtlist": [539], "uid": "2753470833", "dep": 0, "text": " ", "pid": "3747400319453702", "tr": 0, "mid": "3747583643727849", "times": 1, "childnum": 0, "t": 1408977029, "totalChildren": 0, "dr": 0, "children": [], "name": "冯骁骋HIT"}, {"evtlist": [539], "uid": "3904885898", "dep": 0, "text": "", "pid": "3747400319453702", "tr": 0, "mid": "3747725672071601", "times": 1, "childnum": 0, "t": 1409010892, "totalChildren": 0, "dr": 0, "children": [], "name": "川门子"}, {"evtlist": [539], "uid": "1701081555", "dep": 0, "text": "还有一点就是: Logistic Regression虽然叫做“回归”，但log loss其实更常用来做分类问题（特别是二类的分类问题）的baseline。一般来说做回归问题，还是用squared loss的线性回归模型做baseline比较常见。上次被一审稿人狠骂: 你做回归，居然不用logistic regression做baseline？吐槽无力。[黑线]", "pid": "3747400319453702", "tr": 0, "mid": "3756715365784825", "times": 1, "childnum": 0, "t": 1411154201, "totalChildren": 0, "dr": 0, "children": [], "name": "Kipy"}], "name": "王威廉"}