[{"original_text": "//@谢磊NPU: //@52nlp: //@_陈_辉_: 对大数据来说非线性svm基本可以排除，因为复杂度至少O(n^2)，n是训练样本数。大数据分类首选模型是maxent classifier，以及DT based models。如果是超大规模的数据（billion量级），比如点击行为预测，就是logistic regression加在线梯度低降加海量feature加健壮", "username": "晓如微博", "province": 11, "statuses_count": 6948, "friends_count": 1847, "city": 8, "text": "", "user_description": "研究关注可视化、可视分析，探索数据奥秘，洞察万物真相。http://vis.pku.edu.cn/wiki", "mid": "3654969712325799", "verified_reason": "北京大学百人计划研究员袁晓如", "followers_count": 16456, "parent": "", "t": 1386896148, "gender": "m", "verified": true, "verified_type": 0, "uid": "1985499101"}, {"original_text": "//@谢磊NPU: //@52nlp: //@_陈_辉_: 对大数据来说非线性svm基本可以排除，因为复杂度至少O(n^2)，n是训练样本数。大数据分类首选模型是maxent classifier，以及DT based models。如果是超大规模的数据（billion量级），比如点击行为预测，就是logistic regression加在线梯度低降加海量feature加健壮", "username": "xiaoliang008", "province": 81, "statuses_count": 2951, "friends_count": 1150, "city": 2, "text": "", "user_description": "", "mid": "3654970781837650", "verified_reason": "", "followers_count": 179, "parent": "3654969712325799", "t": 1386896403, "gender": "m", "verified": false, "verified_type": -1, "uid": "1780290611"}, {"original_text": "即便不考虑复杂度（包括时间和空间），SVM也不适宜大数据，SVM的优势是解决小样本学习问题。 //@晓如微博: //@谢磊NPU: //@52nlp:", "username": "齐浩亮", "province": 23, "statuses_count": 4675, "friends_count": 300, "city": 1, "text": "即便不考虑复杂度（包括时间和空间），SVM也不适宜大数据，SVM的优势是解决小样本学习问题。 ", "user_description": "黑龙江工程学院，博士，教授", "mid": "3654971608032662", "verified_reason": "黑龙江工程学院副教授", "followers_count": 6539, "parent": "3654969712325799", "t": 1386896600, "gender": "m", "verified": true, "verified_type": 0, "uid": "1874260713"}, {"original_text": "//@谢磊NPU: //@52nlp: //@_陈_辉_: 对大数据来说非线性svm基本可以排除，因为复杂度至少O(n^2)，n是训练样本数。大数据分类首选模型是maxent classifier，以及DT based models。如果是超大规模的数据（billion量级），比如点击行为预测，就是logistic regression加在线梯度低降加海量feature加健壮", "username": "穆鸿hw", "province": 32, "statuses_count": 2857, "friends_count": 1420, "city": 1, "text": "", "user_description": "Big Data、SOA、Cloud Computing", "mid": "3654971809299259", "verified_reason": "", "followers_count": 683, "parent": "3654969712325799", "t": 1386896648, "gender": "m", "verified": false, "verified_type": -1, "uid": "1967133051"}, {"original_text": "//@晓如微博: //@52nlp: //@_陈_辉_: 对大数据来说非线性svm基本可以排除，因为复杂度至少O(n^2)，n是训练样本数。大数据分类首选模型是maxent classifier，以及DT based models。如果是超大规模的数据（billion量级），比如点击行为预测，就是logistic regression加在线梯度低降加海量feature加健壮", "username": "Surfacetoair123", "province": 11, "statuses_count": 22931, "friends_count": 1842, "city": 1, "text": "", "user_description": "", "mid": "3654971947741021", "verified_reason": "", "followers_count": 538, "parent": "3654969712325799", "t": 1386896681, "gender": "m", "verified": false, "verified_type": 220, "uid": "1408233421"}, {"original_text": " //@齐浩亮:即便不考虑复杂度（包括时间和空间），SVM也不适宜大数据，SVM的优势是解决小样本学习问题。 //@晓如微博: //@谢磊NPU: //@52nlp:", "username": "万物皆三NLP", "province": 34, "statuses_count": 1912, "friends_count": 455, "city": 1, "text": " ", "user_description": "汪洋_中科大_科大讯飞研究员。自然语言处理、数据挖掘", "mid": "3654974456343602", "verified_reason": "", "followers_count": 483, "parent": "3654971608032662", "t": 1386897279, "gender": "m", "verified": false, "verified_type": 220, "uid": "2611764075"}, {"original_text": "Estimator for learning linear regressors by Stochastic Gradient Descent//@齐浩亮: 即便不考虑复杂度（包括时间和空间），SVM也不适宜大数据，SVM的优势是解决小样本学习问题。 //@晓如微博: //@谢磊NPU: //@52nlp:", "username": "AI_Ray", "province": 37, "statuses_count": 623, "friends_count": 113, "city": 14, "text": "Estimator for learning linear regressors by Stochastic Gradient Descent", "user_description": "理想、担当、乐观", "mid": "3654975287094693", "verified_reason": "", "followers_count": 229, "parent": "3654971608032662", "t": 1386897477, "gender": "m", "verified": false, "verified_type": 220, "uid": "2448656597"}, {"original_text": "线性SVM和LR也没啥大区别，LR能用，SVM就能用 //@齐浩亮:即便不考虑复杂度（包括时间和空间），SVM也不适宜大数据，SVM的优势是解决小样本学习问题。 //@晓如微博: //@谢磊NPU: //@52nlp:", "username": "张德园", "province": 21, "statuses_count": 3468, "friends_count": 200, "city": 1, "text": "线性SVM和LR也没啥大区别，LR能用，SVM就能用 ", "user_description": "", "mid": "3654976372623652", "verified_reason": "", "followers_count": 262, "parent": "3654971608032662", "t": 1386897739, "gender": "m", "verified": false, "verified_type": -1, "uid": "1994147141"}, {"original_text": "Great Guide!//@_陈_辉_: 对大数据来说非线性svm基本可以排除，因为复杂度至少O(n^2)，n是训练样本数。大数据分类首选模型是maxent classifier，以及DT based models。如果是超大规模的数据（billion量级），比如点击行为预测，就是logistic regression加在线梯度低降加海量feature加健壮", "username": "Capt_Kevin", "province": 11, "statuses_count": 335, "friends_count": 108, "city": 8, "text": "Great Guide!", "user_description": "", "mid": "3654980076306968", "verified_reason": "", "followers_count": 95, "parent": "3654969712325799", "t": 1386898619, "gender": "m", "verified": false, "verified_type": -1, "uid": "1685802410"}, {"original_text": "@_陈_辉_: 对大数据来说非线性svm基本可以排除，因为复杂度至少O(n^2)，n是训练样本数。大数据分类首选模型是maxent classifier，以及DT based models。如果是超大规模的数据（billion量级），比如点击行为预测，就是logistic regression加在线梯度低降加海量feature加健壮", "username": "lbd886", "province": 32, "statuses_count": 158, "friends_count": 137, "city": 1, "text": "@_陈_辉_: 对大数据来说非线性svm基本可以排除，因为复杂度至少O(n^2)，n是训练样本数。大数据分类首选模型是maxent classifier，以及DT based models。如果是超大规模的数据（billion量级），比如点击行为预测，就是logistic regression加在线梯度低降加海量feature加健壮", "user_description": "", "mid": "3654986363618437", "verified_reason": "", "followers_count": 44, "parent": "3654969712325799", "t": 1386900117, "gender": "m", "verified": false, "verified_type": -1, "uid": "2276206724"}, {"original_text": "//@晓如微博: //@谢磊NPU: //@52nlp: //@_陈_辉_: 对大数据来说非线性svm基本可以排除，因为复杂度至少O(n^2)，n是训练样本数。大数据分类首选模型是maxent classifier，以及DT based models。如果是超大规模的数据（billion量级），比如点击行为预测，就是logistic regression加在线梯度低降加。。。", "username": "李锐_ICTIR_IIE", "province": 11, "statuses_count": 715, "friends_count": 241, "city": 8, "text": "", "user_description": "", "mid": "3655000263246398", "verified_reason": "", "followers_count": 510, "parent": "3654969712325799", "t": 1386903432, "gender": "m", "verified": false, "verified_type": -1, "uid": "1866511825"}, {"original_text": "//@李锐_ICTIR_IIE://@晓如微博: //@谢磊NPU: //@52nlp: //@_陈_辉_: 对大数据来说非线性svm基本可以排除，因为复杂度至少O(n^2)，n是训练样本数。大数据分类首选模型是maxent classifier，以及DT based models。如果是超大规模的数据（billion量级），比如点击行为预测，就是logistic regression", "username": "HongyuanMa", "province": 11, "statuses_count": 1741, "friends_count": 202, "city": 8, "text": "", "user_description": "计算所校友。", "mid": "3655000787607867", "verified_reason": "", "followers_count": 394, "parent": "3655000263246398", "t": 1386903556, "gender": "m", "verified": false, "verified_type": 220, "uid": "1951934242"}, {"original_text": "转发微博", "username": "liaoliao_xf", "province": 36, "statuses_count": 1520, "friends_count": 259, "city": 1, "text": "转发微博", "user_description": "", "mid": "3655004377890664", "verified_reason": "", "followers_count": 61, "parent": "3655000263246398", "t": 1386904412, "gender": "m", "verified": false, "verified_type": -1, "uid": "1400013574"}, {"original_text": "//@齐浩亮: 即便不考虑复杂度（包括时间和空间），SVM也不适宜大数据，SVM的优势是解决小样本学习问题。 //@晓如微博: //@谢磊NPU: //@52nlp:", "username": "赵岩Rock", "province": 23, "statuses_count": 1103, "friends_count": 377, "city": 1, "text": "", "user_description": "《C语言点滴》作者，美国德州Fidelis-Group软件经理， homepage: www.hrbxinzhi.com/zhaoyansite", "mid": "3655169185096056", "verified_reason": "前 哈尔滨工业大学软件学院老师", "followers_count": 2542, "parent": "3654971608032662", "t": 1386943709, "gender": "m", "verified": true, "verified_type": 0, "uid": "1753062057"}, {"original_text": "//@谢磊NPU: //@52nlp: //@_陈_辉_: 对大数据来说非线性svm基本可以排除，因为复杂度至少O(n^2)，n是训练样本数。大数据分类首选模型是maxent classifier，以及DT based models。如果是超大规模的数据（billion量级），比如点击行为预测，就是logistic regression加在线梯度低降加海量feature加健壮", "username": "rlq23", "province": 37, "statuses_count": 1536, "friends_count": 633, "city": 1, "text": "", "user_description": "student", "mid": "3655554255420898", "verified_reason": "", "followers_count": 191, "parent": "3654969712325799", "t": 1387035513, "gender": "m", "verified": false, "verified_type": -1, "uid": "1653750652"}, {"original_text": "//@视觉研究: //@齐浩亮: 即便不考虑复杂度（包括时间和空间），SVM也不适宜大数据，SVM的优势是解决小样本学习问题。 //@晓如微博: //@谢磊NPU: //@52nlp:", "username": "吴青松说", "province": 100, "statuses_count": 8387, "friends_count": 133, "city": 1000, "text": "", "user_description": "", "mid": "3657581845696192", "verified_reason": "", "followers_count": 426, "parent": "3657580968839890", "t": 1387518929, "gender": "m", "verified": false, "verified_type": 220, "uid": "1899170775"}, {"original_text": "//@视觉研究: //@齐浩亮: 即便不考虑复杂度（包括时间和空间），SVM也不适宜大数据，SVM的优势是解决小样本学习问题。 //@晓如微博: //@谢磊NPU: //@52nlp:", "username": "无聊的面条", "province": 11, "statuses_count": 3173, "friends_count": 719, "city": 1000, "text": "", "user_description": "", "mid": "3657584252686621", "verified_reason": "", "followers_count": 512, "parent": "3657580968839890", "t": 1387519504, "gender": "m", "verified": false, "verified_type": -1, "uid": "2124455871"}, {"original_text": "mark//@视觉研究://@齐浩亮: 即便不考虑复杂度（包括时间和空间），SVM也不适宜大数据，SVM的优势是解决小样本学习问题。 //@晓如微博: //@谢磊NPU: //@52nlp:", "username": "小诺_Noah", "province": 81, "statuses_count": 6698, "friends_count": 522, "city": 15, "text": "mark", "user_description": "爱关注，爱收集，也爱转发；爱IR，爱NLP，更爱机器学习；欢迎Follow！", "mid": "3657585540908617", "verified_reason": "", "followers_count": 1350, "parent": "3657580968839890", "t": 1387519810, "gender": "m", "verified": false, "verified_type": -1, "uid": "2867879661"}, {"original_text": "//@小诺_pinocchio:mark//@视觉研究://@齐浩亮: 即便不考虑复杂度（包括时间和空间），SVM也不适宜大数据，SVM的优势是解决小样本学习问题。 //@晓如微博: //@谢磊NPU: //@52nlp:", "username": "_胜__", "province": 400, "statuses_count": 3293, "friends_count": 53, "city": 1, "text": "", "user_description": "", "mid": "3657623162988248", "verified_reason": "", "followers_count": 34, "parent": "3657585540908617", "t": 1387528778, "gender": "m", "verified": false, "verified_type": -1, "uid": "2687470097"}, {"original_text": "//@视觉研究://@齐浩亮: 即便不考虑复杂度（包括时间和空间），SVM也不适宜大数据，SVM的优势是解决小样本学习问题。 //@晓如微博: //@谢磊NPU: //@52nlp:", "username": "Noodles-Xu", "province": 31, "statuses_count": 29969, "friends_count": 286, "city": 15, "text": "", "user_description": "成功才快乐", "mid": "3657679408797642", "verified_reason": "", "followers_count": 590, "parent": "3657580968839890", "t": 1387542190, "gender": "m", "verified": false, "verified_type": -1, "uid": "1908599781"}, {"original_text": "//@晓如微博://@谢磊NPU:: //@_陈_辉_: 对大数据来说非线性svm基本可以排除，因为复杂度至少O(n^2)，n是训练样本数。大数据分类首选模型是maxent classifier，以及DT based models。如果是超大规模的数据（billion量级），比如点击行为预测，就是logistic regression加在线梯度低降加海量feature加健壮", "username": "韩启龙-哈尔滨工程大学", "province": 23, "statuses_count": 254, "friends_count": 142, "city": 1, "text": "", "user_description": "哈尔滨工程大学计算机科学与技术学院教授/副院长", "mid": "3678653336772396", "verified_reason": "", "followers_count": 156, "parent": "3654969712325799", "t": 1392542763, "gender": "m", "verified": false, "verified_type": -1, "uid": "1846203601"}]